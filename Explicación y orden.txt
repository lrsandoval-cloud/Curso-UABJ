1) listado.py: localiza las URLs de las páginas de resultados que guardamos
en la carpeta "listados" y genera un archivo TXT con los que corresponden
a cada medio.

2) scraping.py: deben configurarse el sitio (línea 7) y los parámetros (tags y
atributos, líneas 9 a 27) correspondientes al sitio web específico. Captura los contenidos
de los artículos listados y genera un pickle con el dataframe
correspondiente a cada uno en la carpeta 'pickles' (si no existe esta
carpeta, crearla primero)

3) revisa.py: debe configurarse la lista inicial (línea 4) con los nombres
de los medios. Une todos los pickles en uno que se llama "base.pkl" y crea
un archivo "listado.html" con la lista de todos los artículos (id y
título). Este archivo debe abrirse en un browser para detectar los
registros que deban eliminarse. Tomar nota de los ids.

4) depura.py: depura.py: script interactivo. Primero pide los IDs de los
registros a eliminar y después va uno por uno pidiendo confirmación.
Al final reindexa la base y copia el pickle actualizado con el mismo
nombre (base.pkl)

5) lemas.py: además de la librería se necesita descargar el modelo. Desde la
terminal, con la instrucción:

     python -m spacy download es_core_news_sm

   El script ctualiza el pickle base.pkl y le agrega una columna con copetes + textos
   de cada nota lematizados

6) palabras.py: cuenta la frecuencia de cada palabra en los textos lematizados y arma
nubes de tags para cada medio

7) caracteres.py: hace un gráfico con la cantidad de caracteres promedio según medio

8) frecuencias.py: a partir de configurar una keyword genera un gráfico de barras
con la frecuencia de uso de la palabra entre los distintos medios. Debe indicarse la
keyword

9) correlaciones.py: compara la similitud entre las palabras (lematizadas) que se
utilizan, de a pares, entre medio y medio. Devuelve tres resultados:
a) tabla de correlaciones: valor que va de 0 (totalmente disímiles) a 1
(completamente idénticos)
b) gráfico de puntos visualizando la correspondencia entre dos medios (indicar al
comienzo del script cuáles deben compararse)
c) tabla de palabras coincidentes entre medio y medio

10) prepara_sentimientos.py. Asigna los valores de análisis de sentimiento a cada
oración y crea un data frame con todas las oraciones. Este script necesita algunas
librerías que PyCharm no detecta automáticamente para su instalación.
Desde la terminal (uno de los botones de la barra inferior izquierda) indicar:

pip install transformers
pip install torch

(y Enter luego de cada instrucción). También requiere instalar una librería de
nltk, algo que se hace descomentando las líneas 4 y 5 (luego se pueden comentar
de nuevo)

11) sentimientos.py: Este script toma los datos del dataframe recién creado y
los devuelve de diferentes formas:
- tabla de datos generales
- tabla de valores medios según distintos niveles de confianza
- tabla de valores medios según medio
- gráficos de evolución en tiempo para el total y discriminado por medio



